{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'normalize_data_format' from 'keras.utils.conv_utils' (/Users/xiafei/opt/anaconda3/lib/python3.7/site-packages/keras/utils/conv_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b6ac466b16d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_activations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmisc_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinibatchDiscrimination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubPixelUpscaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCustomLRELU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbilinear2x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSubPixelUpscaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/cryptopunksGAN/misc_layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_custom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_output_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_data_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# from keras.backend import normalize_data_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'normalize_data_format' from 'keras.utils.conv_utils' (/Users/xiafei/opt/anaconda3/lib/python3.7/site-packages/keras/utils/conv_utils.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import cv2\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Flatten, Dropout\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "from misc_layers import MinibatchDiscrimination, SubPixelUpscaling, CustomLRELU, bilinear2x\n",
    "from keras_contrib.layers import SubPixelUpscaling\n",
    "import keras.backend as K\n",
    "from keras.initializers import RandomNormal\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "from sklearn.utils import shuffle\n",
    "import scipy\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip uninstall h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow==2.5.0 --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def get_gen_normal(noise_shape):\n",
    "    noise_shape = noise_shape\n",
    "    \n",
    "    kernel_init = 'glorot_uniform'\n",
    "    \n",
    "    gen_input = Input(shape = noise_shape)\n",
    "    generator = Conv2DTranspose(filters = 512, kernel_size = (4,4), strides = (1,1), padding = \"valid\", data_format = \"channels_last\", kernel_initializer = kernel_init)(gen_input)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "        \n",
    "    generator = Conv2DTranspose(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    generator = Conv2DTranspose(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    generator = Conv2DTranspose(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    generator = Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    generator = Conv2DTranspose(filters = 3, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = Activation('tanh')(generator)\n",
    "        \n",
    "    gen_opt = Adam(lr=0.00015, beta_1=0.5)\n",
    "    generator_model = Model(input = gen_input, output = generator)\n",
    "    generator_model.compile(loss='binary_crossentropy', optimizer=gen_opt, metrics=['accuracy'])\n",
    "    generator_model.summary()\n",
    "\n",
    "    return generator_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_normal(image_shape=(64,64,3)):\n",
    "    image_shape = image_shape\n",
    "    \n",
    "    dropout_prob = 0.4\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    dis_input = Input(shape = image_shape)\n",
    "    discriminator = Conv2D(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(dis_input)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "    discriminator = Conv2D(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "   \n",
    "    discriminator = Conv2D(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "    \n",
    "    discriminator = Conv2D(filters = 512, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "    \n",
    "    discriminator = Flatten()(discriminator)\n",
    "    \n",
    "    discriminator = Dense(1)(discriminator)\n",
    "    discriminator = Activation('sigmoid')(discriminator)\n",
    "    #also try the SGD optimiser, might work better for a few learning rates.\n",
    "    dis_opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    discriminator_model = Model(input = dis_input, output = discriminator)\n",
    "    discriminator_model.compile(loss='binary_crossentropy', optimizer=dis_opt, metrics=['accuracy'])\n",
    "    discriminator_model.summary()\n",
    "    return discriminator_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_img(img):\n",
    "    img = (img / 127.5) - 1\n",
    "    #image normalisation to keep values between -1 and 1 for stability\n",
    "    return img\n",
    "\n",
    "def denorm_img(img):\n",
    "    #for output\n",
    "    img = (img + 1) * 127.5\n",
    "    return img.astype(np.uint8) \n",
    "\n",
    "\n",
    "def sample_from_dataset(batch_size, image_shape, data_dir=None, data = None):\n",
    "    sample_dim = (batch_size,) + image_shape\n",
    "    sample = np.empty(sample_dim, dtype=np.float32)\n",
    "    all_data_dirlist = list(glob.glob(data_dir))\n",
    "    sample_imgs_paths = np.random.choice(all_data_dirlist,batch_size)\n",
    "    for index,img_filename in enumerate(sample_imgs_paths):\n",
    "        image = Image.open(img_filename)\n",
    "        image = image.resize(image_shape[:-1])\n",
    "        image = image.convert('RGB')\n",
    "        image = np.asarray(image)\n",
    "        image = norm_img(image)\n",
    "        sample[index,...] = image\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(batch_size, noise_shape):\n",
    "    #input noise for the generator should follow a probability distribution, like in this case, the normal distributon.\n",
    "    return np.random.normal(0, 1, size=(batch_size,)+noise_shape)\n",
    "\n",
    "\n",
    "def generate_images(generator, save_dir):\n",
    "    \n",
    "    noise = gen_noise(batch_size,noise_shape)\n",
    "    fake_data_X = generator.predict(noise)\n",
    "    print(\"Displaying generated images\")\n",
    "    plt.figure(figsize=(4,4))\n",
    "    gs1 = gridspec.GridSpec(4, 4)\n",
    "    gs1.update(wspace=0, hspace=0)\n",
    "    rand_indices = np.random.choice(fake_data_X.shape[0],16,replace=False)\n",
    "    for i in range(16):\n",
    "        #plt.subplot(4, 4, i+1)\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        ax1.set_aspect('equal')\n",
    "        rand_index = rand_indices[i]\n",
    "        image = fake_data_X[rand_index, :,:,:]\n",
    "        fig = plt.imshow(denorm_img(image))\n",
    "        plt.axis('off')\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir+str(time.time())+\"_GENimage.png\",bbox_inches='tight',pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img_batch(img_batch,img_save_dir):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    gs1 = gridspec.GridSpec(4, 4)\n",
    "    gs1.update(wspace=0, hspace=0)\n",
    "    rand_indices = np.random.choice(img_batch.shape[0],16,replace=False)\n",
    "    for i in range(16):\n",
    "        #plt.subplot(4, 4, i+1)\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        ax1.set_aspect('equal')\n",
    "        rand_index = rand_indices[i]\n",
    "        image = img_batch[rand_index, :,:,:]\n",
    "        fig = plt.imshow(denorm_img(image))\n",
    "        plt.axis('off')\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(img_save_dir,bbox_inches='tight',pad_inches=0)\n",
    "    plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_shape = (1,1,100)\n",
    "num_steps = 10000\n",
    "batch_size = 64\n",
    "image_shape = None\n",
    "img_save_dir = \"./generated/\"\n",
    "save_model = True\n",
    "image_shape = (64,64,3)\n",
    "data_dir =  \"./images/*.png\"\n",
    "\n",
    "log_dir = img_save_dir\n",
    "save_model_dir = img_save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiafei/opt/anaconda3/envs/mytensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         2097664   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,768,321\n",
      "Trainable params: 2,766,529\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 4, 4, 512)         819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 8, 8, 256)         2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 16, 16, 128)       524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 64, 64, 3)         3075      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 3)         0         \n",
      "=================================================================\n",
      "Total params: 3,616,771\n",
      "Trainable params: 3,614,723\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiafei/opt/anaconda3/envs/mytensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "discriminator = get_disc_normal(image_shape)\n",
    "generator = get_gen_normal(noise_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 64, 64, 3)         3616771   \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 2768321   \n",
      "=================================================================\n",
      "Total params: 6,385,092\n",
      "Trainable params: 3,614,723\n",
      "Non-trainable params: 2,770,369\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiafei/opt/anaconda3/envs/mytensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"mo..., inputs=Tensor(\"in...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "opt = Adam(lr=0.00015, beta_1=0.5) \n",
    "gen_inp = Input(shape=noise_shape)\n",
    "GAN_inp = generator(gen_inp)\n",
    "GAN_opt = discriminator(GAN_inp)\n",
    "gan = Model(input = gen_inp, output = GAN_opt)\n",
    "gan.compile(loss = 'binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_disc_fake_loss = deque([0], maxlen=250)     \n",
    "avg_disc_real_loss = deque([0], maxlen=250)\n",
    "avg_GAN_loss = deque([0], maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin step:  0\n"
     ]
    }
   ],
   "source": [
    "for step in range(num_steps): \n",
    "    tot_step = step\n",
    "    print(\"Begin step: \", tot_step)\n",
    "    step_begin_time = time.time() \n",
    "    \n",
    "    real_data_X = sample_from_dataset(batch_size, image_shape, data_dir = data_dir)\n",
    "\n",
    "    noise = gen_noise(batch_size,noise_shape)\n",
    "    \n",
    "    fake_data_X = generator.predict(noise)\n",
    "    \n",
    "    if (tot_step % 10) == 0:\n",
    "        step_num = str(tot_step).zfill(4)\n",
    "        save_img_batch(fake_data_X,img_save_dir+step_num+\"_image.png\")\n",
    "\n",
    "    #concatenate real and fake data samples    \n",
    "    data_X = np.concatenate([real_data_X,fake_data_X])\n",
    "    #add noise to the label inputs\n",
    "    real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
    "    \n",
    "    \n",
    "    fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
    "     \n",
    "    data_Y = np.concatenate((real_data_Y,fake_data_Y))\n",
    "        \n",
    "    discriminator.trainable = True\n",
    "    generator.trainable = False\n",
    "    #training the discriminator on real and fake data can be done together, i.e., \n",
    "    #on the data_x and data_y, OR it can be done \n",
    "    #one by one as performed below. This is the safer choice and gives better results \n",
    "    #as compared to combining the real and generated samples.\n",
    "    dis_metrics_real = discriminator.train_on_batch(real_data_X,real_data_Y)  \n",
    "    dis_metrics_fake = discriminator.train_on_batch(fake_data_X,fake_data_Y)   \n",
    "    \n",
    "    print(\"Disc: real loss: %f fake loss: %f\" % (dis_metrics_real[0], dis_metrics_fake[0]))\n",
    "    \n",
    "    \n",
    "    avg_disc_fake_loss.append(dis_metrics_fake[0])\n",
    "    avg_disc_real_loss.append(dis_metrics_real[0])\n",
    "    \n",
    "    generator.trainable = True\n",
    "\n",
    "    GAN_X = gen_noise(batch_size,noise_shape)\n",
    "\n",
    "    GAN_Y = real_data_Y\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    gan_metrics = gan.train_on_batch(GAN_X,GAN_Y)\n",
    "    print(\"GAN loss: %f\" % (gan_metrics[0]))\n",
    "    \n",
    "    text_file = open(log_dir+\"\\\\training_log.txt\", \"a\")\n",
    "    text_file.write(\"Step: %d Disc: real loss: %f fake loss: %f GAN loss: %f\\n\" % (tot_step, dis_metrics_real[0],\n",
    "                                                                                   dis_metrics_fake[0],gan_metrics[0]))\n",
    "    text_file.close()\n",
    "    avg_GAN_loss.append(gan_metrics[0])\n",
    "    \n",
    "        \n",
    "    end_time = time.time()\n",
    "    diff_time = int(end_time - step_begin_time)\n",
    "    print(\"Step %d completed. Time took: %s secs.\" % (tot_step, diff_time))\n",
    "    \n",
    "    if ((tot_step+1) % 500) == 0:\n",
    "        print(\"-----------------------------------------------------------------\")\n",
    "        print(\"Average Disc_fake loss: %f\" % (np.mean(avg_disc_fake_loss)))    \n",
    "        print(\"Average Disc_real loss: %f\" % (np.mean(avg_disc_real_loss)))    \n",
    "        print(\"Average GAN loss: %f\" % (np.mean(avg_GAN_loss)))\n",
    "        print(\"-----------------------------------------------------------------\")\n",
    "        discriminator.trainable = True\n",
    "        generator.trainable = True\n",
    "        generator.save(save_model_dir+str(tot_step)+\"_GENERATOR_weights_and_arch.hdf5\")\n",
    "        discriminator.save(save_model_dir+str(tot_step)+\"_DISCRIMINATOR_weights_and_arch.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
